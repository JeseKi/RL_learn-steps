{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854eb06c",
   "metadata": {},
   "source": [
    "# 导入必要库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from core import RLEnv\n",
    "from core.agent import BaseAgent\n",
    "from greedy import (\n",
    "    EpsilonDecreasingConfig,\n",
    "    GreedyAgent,\n",
    "    greedy_average,\n",
    "    epsilon_average,\n",
    "    epsilon_decreasing_average,\n",
    ")\n",
    "from ucb1 import UCBAgent, ucb1\n",
    "from thompson_sampling import TSAgent\n",
    "\n",
    "from train import batch_train\n",
    "from utils import plot_metrics_history, save_experiment_data, ProcessDataLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS: int = 100_000\n",
    "GRID_SIZE: int = 500\n",
    "\n",
    "SEED: int = 42\n",
    "MACHINE_COUNT: int = 10\n",
    "COUNT: int = 50\n",
    "CONVERGENCE_THRESHOLD: float = 0.9\n",
    "CONVERGENCE_MIN_STEPS: int = 100\n",
    "OPTIMISTIC_TIMES: int = 1\n",
    "ENABLE_OPTIMISTIC: bool = True\n",
    "EXPERIMENT_DATA_DIR: Path = Path.cwd() / \"experiment_data\"\n",
    "\n",
    "ENV: RLEnv = RLEnv(machine_count=MACHINE_COUNT, seed=SEED)\n",
    "EPSILON_CONFIG: EpsilonDecreasingConfig = EpsilonDecreasingConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e091e",
   "metadata": {},
   "source": [
    "# 工厂函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e2844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_id(agent_name: str) -> str:\n",
    "    return agent_name + str(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_greedy_agent(\n",
    "    env: RLEnv, \n",
    "    epsilon_config: EpsilonDecreasingConfig, \n",
    "    optimistic_init: bool, \n",
    "    optimistic_times: int,\n",
    "    convergence_threshold: float,\n",
    "    convergence_min_steps: int,\n",
    "    seed: int,\n",
    ") -> BaseAgent:\n",
    "    return GreedyAgent(\n",
    "        name=greedy_average.__name__,\n",
    "        env=env,\n",
    "        greedy_algorithm=greedy_average,\n",
    "        epsilon_config=epsilon_config,\n",
    "        optimistic_init=optimistic_init,\n",
    "        optimistic_times=optimistic_times,\n",
    "        convergence_threshold=convergence_threshold,\n",
    "        convergence_min_steps=convergence_min_steps,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "def create_epsilon_agent(\n",
    "    env: RLEnv, \n",
    "    epsilon_config: EpsilonDecreasingConfig, \n",
    "    optimistic_init: bool, \n",
    "    optimistic_times: int,\n",
    "    convergence_threshold: float,\n",
    "    convergence_min_steps: int,\n",
    "    seed: int,\n",
    ") -> BaseAgent:\n",
    "    return GreedyAgent(\n",
    "        name=epsilon_average.__name__,\n",
    "        env=env,\n",
    "        greedy_algorithm=epsilon_average,\n",
    "        epsilon_config=epsilon_config,\n",
    "        optimistic_init=optimistic_init,\n",
    "        optimistic_times=optimistic_times,\n",
    "        convergence_threshold=convergence_threshold,\n",
    "        convergence_min_steps=convergence_min_steps,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "def create_decreasing_agent(\n",
    "    env: RLEnv, \n",
    "    epsilon_config: EpsilonDecreasingConfig, \n",
    "    optimistic_init: bool, \n",
    "    optimistic_times: int,\n",
    "    convergence_threshold: float,\n",
    "    convergence_min_steps: int,\n",
    "    seed: int,\n",
    ") -> BaseAgent:\n",
    "    return GreedyAgent(\n",
    "        name=epsilon_decreasing_average.__name__,\n",
    "        env=env,\n",
    "        greedy_algorithm=epsilon_decreasing_average,\n",
    "        epsilon_config=epsilon_config,\n",
    "        optimistic_init=optimistic_init,\n",
    "        optimistic_times=optimistic_times,\n",
    "        convergence_threshold=convergence_threshold,\n",
    "        convergence_min_steps=convergence_min_steps,\n",
    "        seed=seed,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ucb1_agent(\n",
    "    env: RLEnv,\n",
    "    convergence_threshold: float,\n",
    "    convergence_min_steps: int,\n",
    "    seed: int,\n",
    ") -> BaseAgent:\n",
    "    return UCBAgent(\n",
    "        name=ucb1.__name__,\n",
    "        env=env,\n",
    "        ucb1_algorithm=ucb1,\n",
    "        convergence_threshold=convergence_threshold,\n",
    "        convergence_min_steps=convergence_min_steps,\n",
    "        seed=seed,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a4c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ts_agent(\n",
    "    env: RLEnv,\n",
    "    convergence_threshold: float,\n",
    "    convergence_min_steps: int,\n",
    "    seed: int,\n",
    ") -> BaseAgent:\n",
    "    return TSAgent(\n",
    "        name=TSAgent.__name__,\n",
    "        env=env,\n",
    "        convergence_threshold=convergence_threshold,\n",
    "        convergence_min_steps=convergence_min_steps,\n",
    "        seed=seed,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0e0bb",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6993f9fc",
   "metadata": {},
   "source": [
    "## 普通贪婪算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = get_run_id(greedy_average.__name__)\n",
    "file_name: Path =EXPERIMENT_DATA_DIR / f\"{run_id}_T={STEPS}_K={MACHINE_COUNT}_Q_0={OPTIMISTIC_TIMES}.png\"\n",
    "process_logger = ProcessDataLogger(\n",
    "    run_id=run_id,\n",
    "    total_steps=STEPS,\n",
    "    grid_size=GRID_SIZE,\n",
    ")\n",
    "\n",
    "agents, reward, metrics = batch_train(\n",
    "    count=COUNT,\n",
    "    agent_factory=create_greedy_agent,\n",
    "    env=ENV,\n",
    "    epsilon_config=EPSILON_CONFIG,\n",
    "    steps=STEPS,\n",
    "    seed=SEED,\n",
    "    optimistic_init=ENABLE_OPTIMISTIC,\n",
    "    optimistic_times=OPTIMISTIC_TIMES,\n",
    "    convergence_threshold=CONVERGENCE_THRESHOLD,\n",
    "    convergence_min_steps=CONVERGENCE_MIN_STEPS,\n",
    "    process_logger=process_logger\n",
    ")\n",
    "print(metrics)\n",
    "print(reward)\n",
    "\n",
    "plot_metrics_history(agents, run_id, file_name)\n",
    "save_experiment_data(reward, metrics, file_name)\n",
    "process_logger.save(file_name.with_stem(file_name.stem + \"process\"), total_steps=STEPS)\n",
    "dump = process_logger.export(total_steps=STEPS)\n",
    "keys = list(dump.points[0].data.keys())\n",
    "\n",
    "del agents, reward, metrics, process_logger, dump\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d0fa0",
   "metadata": {},
   "source": [
    "## UCB1算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = get_run_id(ucb1.__name__)\n",
    "file_name: Path =EXPERIMENT_DATA_DIR / f\"{run_id}_T={STEPS}_K={MACHINE_COUNT}_Q_0={OPTIMISTIC_TIMES}.png\"\n",
    "process_logger = ProcessDataLogger(\n",
    "    run_id=run_id,\n",
    "    total_steps=STEPS,\n",
    "    grid_size=GRID_SIZE,\n",
    ")\n",
    "\n",
    "agents, reward, metrics = batch_train(\n",
    "    count=COUNT,\n",
    "    agent_factory=create_ucb1_agent,\n",
    "    env=ENV,\n",
    "    steps=STEPS,\n",
    "    seed=SEED,\n",
    "    convergence_threshold=CONVERGENCE_THRESHOLD,\n",
    "    convergence_min_steps=CONVERGENCE_MIN_STEPS,\n",
    "    process_logger=process_logger,\n",
    ")\n",
    "print(metrics)\n",
    "print(reward)\n",
    "\n",
    "plot_metrics_history(agents, run_id, file_name)\n",
    "save_experiment_data(reward, metrics, file_name)\n",
    "process_logger.save(file_name.with_stem(file_name.stem + \"process\"), total_steps=STEPS)\n",
    "dump = process_logger.export(total_steps=STEPS)\n",
    "keys = list(dump.points[0].data.keys())\n",
    "\n",
    "del agents, reward, metrics, process_logger, dump\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ffd59",
   "metadata": {},
   "source": [
    "# Thompson Sampling 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = get_run_id(\"thompson_sampling\")\n",
    "file_name: Path =EXPERIMENT_DATA_DIR / f\"{run_id}_T={STEPS}_K={MACHINE_COUNT}_Q_0={OPTIMISTIC_TIMES}.png\"\n",
    "process_logger = ProcessDataLogger(\n",
    "    run_id=run_id,\n",
    "    total_steps=STEPS,\n",
    "    grid_size=GRID_SIZE,\n",
    ")\n",
    "\n",
    "agents, reward, metrics = batch_train(\n",
    "    count=COUNT,\n",
    "    agent_factory=create_ts_agent,\n",
    "    env=ENV,\n",
    "    steps=STEPS,\n",
    "    seed=SEED,\n",
    "    convergence_threshold=CONVERGENCE_THRESHOLD,\n",
    "    convergence_min_steps=CONVERGENCE_MIN_STEPS,\n",
    "    process_logger=process_logger,\n",
    ")\n",
    "print(metrics)\n",
    "print(reward)\n",
    "\n",
    "plot_metrics_history(agents, run_id, file_name)\n",
    "save_experiment_data(reward, metrics, file_name)\n",
    "process_logger.save(file_name.with_stem(file_name.stem + \"process\"), total_steps=STEPS)\n",
    "dump = process_logger.export(total_steps=STEPS)\n",
    "keys = list(dump.points[0].data.keys())\n",
    "\n",
    "del agents, reward, metrics, process_logger, dump\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
