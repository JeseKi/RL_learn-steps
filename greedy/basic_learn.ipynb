{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e3bcc5",
   "metadata": {},
   "source": [
    "# 贪婪算法的不同和优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca6aed0",
   "metadata": {},
   "source": [
    "## 现在将创建不同的 Agent 并统计平均值，后悔值，命中率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8b76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "from core import EpsilonDecreasingConfig, GreedyAgent, Rewards, RLEnv\n",
    "from train import train, AverageMetrics\n",
    "from algorithms import (\n",
    "    greedy_normal,\n",
    "    epsilon_greedy,\n",
    "    epsilon_decreasing_greedy,\n",
    "    greedy_average,\n",
    "    epsilon_average,\n",
    "    epsilon_decreasing_average,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7795a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "env = RLEnv(seed=SEED)\n",
    "COUNT = 50\n",
    "STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(\n",
    "    count: int,\n",
    "    greedy_algorithm: Callable[..., int],\n",
    "    env: RLEnv,\n",
    "    epsilon_config: EpsilonDecreasingConfig,\n",
    "    steps: int,\n",
    "    seed: int,\n",
    ") -> Tuple[List[GreedyAgent], Rewards, AverageMetrics]:\n",
    "    \"\"\"批训练 Agent，传入数量，不同的算法，环境，步数和初始种子即可训练\n",
    "\n",
    "    Args:\n",
    "        count (int): 训练数量\n",
    "        agent (GreedyAgent): 算法 类型\n",
    "        env (RLEnv): 环境\n",
    "        steps (int): 步数\n",
    "        seed (int): 初始种子\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[GreedyAgent], Rewards]: 返回训练后的 agents 和平均后的奖励\n",
    "    \"\"\"\n",
    "    _agents: List[GreedyAgent] = []\n",
    "\n",
    "    if not callable(greedy_algorithm):\n",
    "        raise ValueError(\"算法必须传入一个函数\")\n",
    "\n",
    "    for i in range(count):\n",
    "        _agents.append(\n",
    "            GreedyAgent(\n",
    "                name=greedy_algorithm.__name__,  # type: ignore # 在 callable 这里就已经验证了是一个函数，这里是为了避免 ty 工具误报\n",
    "                env=env,\n",
    "                greedy_algorithm=greedy_algorithm,\n",
    "                epsilon_config=epsilon_config,\n",
    "                seed=seed + i,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    agents, reward, metrics = train(_agents, steps)\n",
    "\n",
    "    return agents, reward, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be871e68",
   "metadata": {},
   "source": [
    "## 累积奖励"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2bbf54",
   "metadata": {},
   "source": [
    "### 普通贪婪算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3bc5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anget 名称: greedy_normal\n",
      "平均奖励：Rewards(values=[90.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], counts=[1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
      "指标：AverageMetrics(avg_regret=818.8709090909091, avg_regret_rate=0.9007579999999998, avg_total_reward=90.22, avg_optimal_rate=0.0)\n"
     ]
    }
   ],
   "source": [
    "# 普通贪婪算法的结果\n",
    "agnts, reward, metrics = batch_train(\n",
    "    count=COUNT,\n",
    "    greedy_algorithm=greedy_normal,\n",
    "    env=env,\n",
    "    epsilon_config=EpsilonDecreasingConfig(),\n",
    "    steps=STEPS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"anget 名称: {agnts[0].name}\\n平均奖励：{reward}\\n指标：{metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf6dfb",
   "metadata": {},
   "source": [
    "### 随机探索贪婪算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf50cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anget 名称: epsilon_greedy\n",
      "平均奖励：Rewards(values=[41.9, 4.9, 7.46, 35.92, 20.38, 23.6, 50.8, 46.7, 52.02, 91.64], counts=[445.28, 27.96, 27.84, 99.06, 46.16, 44.22, 80.8, 64.38, 63.72, 100.58])\n",
      "指标：AverageMetrics(avg_regret=533.7709090909085, avg_regret_rate=0.5871479999999998, avg_total_reward=375.32, avg_optimal_rate=0.10057999999999997)\n"
     ]
    }
   ],
   "source": [
    "# 随机探索贪婪算法的结果\n",
    "agnts, reward, metrics = batch_train(\n",
    "    count=COUNT,\n",
    "    greedy_algorithm=epsilon_greedy,\n",
    "    env=env,\n",
    "    epsilon_config=EpsilonDecreasingConfig(),\n",
    "    steps=STEPS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"anget 名称: {agnts[0].name}\\n平均奖励：{reward}\\n指标：{metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46159aae",
   "metadata": {},
   "source": [
    "### 退火随机探索贪婪算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a13580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anget 名称: epsilon_decreasing_greedy\n",
      "平均奖励：Rewards(values=[2.04, 6.72, 13.56, 7.06, 30.56, 63.26, 104.98, 97.02, 201.04, 133.52], counts=[18.76, 36.82, 51.22, 20.02, 67.82, 115.8, 165.12, 132.28, 245.14, 147.02])\n",
      "指标：AverageMetrics(avg_regret=249.33090909090876, avg_regret_rate=0.2742639999999999, avg_total_reward=659.76, avg_optimal_rate=0.14701999999999996)\n"
     ]
    }
   ],
   "source": [
    "agnts, reward, metrics = batch_train(\n",
    "    count=COUNT,\n",
    "    greedy_algorithm=epsilon_decreasing_greedy,\n",
    "    env=env,\n",
    "    epsilon_config=EpsilonDecreasingConfig(),\n",
    "    steps=STEPS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"anget 名称: {agnts[0].name}\\n平均奖励：{reward}\\n指标：{metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e98076",
   "metadata": {},
   "source": [
    "## 平均奖励"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c2c88b",
   "metadata": {},
   "source": [
    "### 普通贪婪算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d766b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anget 名称: greedy_average\n",
      "平均奖励：Rewards(values=[91.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], counts=[1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
      "指标：AverageMetrics(avg_regret=817.6709090909089, avg_regret_rate=0.899438, avg_total_reward=91.42, avg_optimal_rate=0.0)\n"
     ]
    }
   ],
   "source": [
    "# 普通贪婪算法的结果\n",
    "agnts, reward, metrics = batch_train(\n",
    "    count=COUNT,\n",
    "    greedy_algorithm=greedy_average,\n",
    "    env=env,\n",
    "    epsilon_config=EpsilonDecreasingConfig(),\n",
    "    steps=STEPS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"anget 名称: {agnts[0].name}\\n平均奖励：{reward}\\n指标：{metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ccd67",
   "metadata": {},
   "source": [
    "### 随机探索贪婪算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ffe04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anget 名称: epsilon_average\n",
      "平均奖励：Rewards(values=[2.7, 1.86, 3.32, 4.82, 6.18, 7.66, 13.6, 27.66, 167.46, 585.36], counts=[29.44, 10.44, 11.0, 13.02, 13.28, 14.72, 21.62, 38.22, 203.9, 644.36])\n",
      "指标：AverageMetrics(avg_regret=88.470909090909, avg_regret_rate=0.09731799999999996, avg_total_reward=820.62, avg_optimal_rate=0.64436)\n"
     ]
    }
   ],
   "source": [
    "# 随机探索贪婪算法的结果\n",
    "agnts, reward, metrics = batch_train(\n",
    "    count=COUNT,\n",
    "    greedy_algorithm=epsilon_average,\n",
    "    env=env,\n",
    "    epsilon_config=EpsilonDecreasingConfig(),\n",
    "    steps=STEPS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"anget 名称: {agnts[0].name}\\n平均奖励：{reward}\\n指标：{metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc5294",
   "metadata": {},
   "source": [
    "### 退火随机探索贪婪算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e480b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anget 名称: epsilon_decreasing_average\n",
      "平均奖励：Rewards(values=[1.62, 3.92, 4.8, 7.46, 9.02, 11.04, 14.76, 15.74, 91.86, 655.74], counts=[18.7, 20.7, 18.94, 20.3, 19.86, 20.1, 23.04, 22.5, 111.84, 724.02])\n",
      "指标：AverageMetrics(avg_regret=93.13090909090901, avg_regret_rate=0.10244399999999995, avg_total_reward=815.96, avg_optimal_rate=0.72402)\n"
     ]
    }
   ],
   "source": [
    "agnts, reward, metrics = batch_train(\n",
    "    count=COUNT,\n",
    "    greedy_algorithm=epsilon_decreasing_average,\n",
    "    env=env,\n",
    "    epsilon_config=EpsilonDecreasingConfig(),\n",
    "    steps=STEPS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"anget 名称: {agnts[0].name}\\n平均奖励：{reward}\\n指标：{metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
